# **Journey of 300DaysOfData in Machine Learning and Deep Learning**
**Day1 of 300DaysOfData!**
- **Gradient Descent and Cross Validation**: Gradient Descent is an iterative approach to approximating the Parameters that minimize a Differentiable Loss Function. Cross Validation is a resampling procedure used to evaluate Machine Learning Models on a limited Data sample which has a parameter that splits the data into number of groups. On my Journey of Machine Learning and Deep Learning, Today I have read in brief about the fundamental Topics such as Calculus, Matrices, Matrix Calculus, Random Variables, Density Functions, Distributions, Independence, Maximum Likelihood Estimation and Conditional Probability. I have also read and Implemented about Gradient Descent and Cross Validation. I am starting this Journey from Scratch and I am following the Book:**Machine Learning From Scratch**. I have presented the Implementation of Gradient Descent and Cross Validation here in the Snapshots. I hope you will also spend some time reading the Topics from the Book mentioned above. I am excited about the days to come!!
- Book:
  - [**Machine Learning From Scratch**](https://dafriedman97.github.io/mlbook/content/introduction.html)

![Image](https://github.com/ThinamXx/300Days__MachineLearningDeepLearning/blob/main/Images/Day%201.PNG)

**Day2 of 300DaysOfData!**
- **Ordinary Linear Regression**: Linear Regression is a linear approach to modelling the relationships between a scalar response or dependent variable and one or more explanatory variables or independent variables. On my Journey of Machine Learning and Deep Learning, Today I have read and Implemented about Ordinary Linear Regression, Parameter Estimation, Minimizing Loss and Maximizing Likelihood along with the Construction and Implementation of the LR from the Book **Machine Learning From Scratch**. I have also started reading the Book **A Comprehensive Guide to Machine Learning** which focuses on Mathematics and Theory behind the Topics. I have read about Regression, Ordinary Least Squares, Vector Calculus, Orthogonal Projection, Ridge Regression, Feature Engineering, Fitting Ellipses, Polynomial Features, Hyperparameters and Validation, Errors and Cross Validation from this book. I have presented the Implementation of Linear Regression along with Visualizations using Python here in the Snapshots. I hope you will also spend some time reading the Topics and Books mentioned above. Excited about the days ahead!!
- Books:
  - [**Machine Learning From Scratch**](https://dafriedman97.github.io/mlbook/content/introduction.html)
  - **A Comprehensive Guide to Machine Learning**

![Image](https://github.com/ThinamXx/300Days__MachineLearningDeepLearning/blob/main/Images/Day%202a.PNG)

![Image](https://github.com/ThinamXx/300Days__MachineLearningDeepLearning/blob/main/Images/Day%202b.PNG)

**Day3 of 300DaysOfData!**
- On my Journey of Machine Learning and Deep Learning, Today I have read and Implemented about Regularized Regression such as Ridge Regression and Lasso Regression, Bayesian Regression, GLMs, Poisson Regression along with Construction and Implementation of the same from the Book **Machine Learning From Scratch**. I have also read the Book **A Comprehensive Guide to Machine Learning** which focuses on Mathematics and Theory behind the Topics. I have read about Maximum Likelihood Estimation or MLE and Maximum a Posteriori or MAE for Regression, Probabilistic Model, Bias Variance Tradeoff, Metrics, Bias Variance Decomposition, Alternative Decomposition, Multivariate Gaussians, Estimating Gaussians from Data, Weighted Least Squares, Ridge Regression, and Generalized Least Squares from this Book. I have presented the Implementation of Ridge Regression, Lasso Regression along with Cross Validation, Bayesian Regression and Poisson Regression using Python here in the Snapshot. I hope you will also spend some time reading the Topics and Books mentioned above. Excited about the days ahead!!
- Books:
  - [**Machine Learning From Scratch**](https://dafriedman97.github.io/mlbook/content/introduction.html)
  - **A Comprehensive Guide to Machine Learning**

![Image](https://github.com/ThinamXx/300Days__MachineLearningDeepLearning/blob/main/Images/Day%203.PNG)

**Day4 of 300DaysOfData!**
- On my Journey of Machine Learning and Deep Learning, Today I have read and Implemented about Discriminative Classifiers such as Binary and Multiclass Logistic Regression, The Perceptron Algorithm, Parameter Estimation, Fishers Linear Discriminant and Fisher Criterion along with Construction and Implementation of the same from the Book **Machine Learning From Scratch**. I have also read the Book **A Comprehensive Guide to Machine Learning** which focuses on Mathematics and Theory behind the Topics. I have read about Kernels and Ridge Regression, Linear Algebra Derivation, Computational Analysis, Sparse Least Squares, Orthogonal Matching Pursuit, Total Least Squares, Low rank Formulation, Dimensionality Reduction, Principal Component Analysis, Projection, Changing Coordinates, Minimizing Reconstruction Errors and Probabilistic PCA from this Book. I have presented the Implementation of Binary and Multiclass Logistic Regression, The Perceptron Algorithm and Fishers Linear Discriminant using Python here in the Snapshot. I hope you will also spend some time reading the Topics and Books mentioned above. Excited about the days ahead!!
- Books:
  - [**Machine Learning From Scratch**](https://dafriedman97.github.io/mlbook/content/introduction.html)
  - **A Comprehensive Guide to Machine Learning**

![Image](https://github.com/ThinamXx/300Days__MachineLearningDeepLearning/blob/main/Images/Day%204.PNG)

**Day5 of 300DaysOfData!**
- On my Journey of Machine Learning and Deep Learning, Today I have read and Implemented about Generative Classifiers such as Linear Discriminative Analysis or LDA, Quadratic Discriminative Analysis or QDA, Naive Bayes, Parameter Estimation and Data Likelihood along with Construction and Implementation of the same from the Book **Machine Learning From Scratch**. I have also read the Book **A Comprehensive Guide to Machine Learning** which focuses on Mathematics and Theory behind the Topics. I have read about Generative and Discriminative Classification, Bayes Decision Rule, Least Squares Support Vector Machines, Feature Extension, Neural Network Extension, Binary and Multiclass Logistic Regression, Loss Function, Training, Multiclass Extension, Gaussian Discriminant Analysis, QDA and LDA Classification and Support Vector Machines from this Book. I have presented the Implementation of LDA, QDA and Naive Bayes along with Visualizations using Python here in the Snapshot. I hope you will also spend some time reading the Topics and Books mentioned above. Excited about the days ahead!!
- Books:
  - [**Machine Learning From Scratch**](https://dafriedman97.github.io/mlbook/content/introduction.html)
  - **A Comprehensive Guide to Machine Learning**

![Image](https://github.com/ThinamXx/300Days__MachineLearningDeepLearning/blob/main/Images/Day%205.PNG)

**Day6 of 300DaysOfData!**
- **Decision Trees**: A Decision Tree is an interpretable machine learning for Regression and Classification. It is a flow chart like structure in which each internal node represents a Test on an attribute and each branch represents the outcome of the Test. On my Journey of Machine Learning and Deep Learning, Today I have read about Decision Trees such as Regression Trees and Classification Trees, Building Trees, Making Splits and Predictions, Hyperparameters, Pruning and Regularization along with Construction and Implementation of the same from the Book **Machine Learning From Scratch**. I have also read the Book **A Comprehensive Guide to Machine Learning** which focuses on Mathematics and Theory behind the Topics. I have read about Decision Tree Learning, Entropy and Information, Gini Impurity, Stopping Criteria, Random Forests, Boosting and AdaBoost, Gradient Boosting and KMeans Clustering from this Book. I have presented the Implementation of Regression Trees and Classification Trees using Python here in the Snapshot. I hope you will also spend some time reading the Topics and Books mentioned above. Excited about the days ahead!!
- Books:
  - [**Machine Learning From Scratch**](https://dafriedman97.github.io/mlbook/content/introduction.html)
  - **A Comprehensive Guide to Machine Learning**

![Image](https://github.com/ThinamXx/300Days__MachineLearningDeepLearning/blob/main/Images/Day%206.PNG)

**Day7 of 300DaysOfData!**
- **Tree Ensemble Methods**: Ensemble Methods combine the outputs of multiple simple Models which is often called Learners in order to create the fine Model with low variance. Due to their high variance, a decision trees often fail to reach a level of precision comparable to other predictive algorithms and Ensemble Methods minimize the variance. On my Journey of Machine Learning and Deep Learning, Today I have read and Implemented about Tree Ensemble Methods such as Bagging for Decision Trees, Bootstrapping, Random Forests and Procedure, Boosting, AdaBoost for Binary Classification, Weighted Classification Trees, The Discrete AdaBoost Algorithm and AdaBoost for Regression along with Construction and Implementation of the same from the Book **Machine Learning From Scratch**. I have presented the Implementation of Bagging, Random Forests and AdaBoost along with different base estimators using Python here in the Snapshot. I hope you will also spend some time reading the Topics and Book mentioned above. Excited about the days ahead !!
- Books:
  - [**Machine Learning From Scratch**](https://dafriedman97.github.io/mlbook/content/introduction.html)

![Image](https://github.com/ThinamXx/300Days__MachineLearningDeepLearning/blob/main/Images/Day%207.PNG)

**Day8 of 300DaysOfData!**
- On my Journey of Machine Learning and Deep Learning, Today I have read and Implemented about Neural Networks from the Book **Machine Learning From Scratch**. I have read about Model Structure, Communication between Layers, Activation Functions such as ReLU, Sigmoid, The Linear Activation Function, Optimization, Back Propagation, Calculating Gradients, Chain Rule and Observations, Loss Functions along with Construction using The Loop Approach and The Matrix Approach and Implementation of the same from this Book. I have also read the Book **A Comprehensive Guide to Machine Learning** which focuses on Mathematics and Theory behind the Topics. I have read about Convolutional Neural Networks and Layers, Pooling Layers, Back Propagation for CNN, ResNet and Visual Understanding of CNNs from this Book. Besides, I have seen a couple of videos of Neural Networks and Deep Learning. I have presented the simple Implementation of Neural Networks with The Functional API and The Sequential API using TensorFlow here in the Snapshot. I hope you will also spend some time reading the Topics and Books mentioned above. Excited about the days ahead !!
- Books:
  - [**Machine Learning From Scratch**](https://dafriedman97.github.io/mlbook/content/introduction.html)
  - **A Comprehensive Guide to Machine Learning**

![Image](https://github.com/ThinamXx/300Days__MachineLearningDeepLearning/blob/main/Images/Day%208.PNG)

**Day9 of 300DaysOfData!**
- **Reinforcement Learning**: In Reinforcement Learning, The Learning system called an agent in a particular context can observe the environment, select and perform actions and get rewards in return or penalties in the form of negative rewards. It must learn by itself what is the best policy to get the most reward over time. On my Journey of Machine Learning and Deep Learning, Today I have started reading and Implementing from the Book **Hands On Machine Learning with Scikit Learn, Keras and TensorFlow**. I have read briefly about The Machine Learning Landscape viz. Types of Machine Learning Systems such as Supervised and Unsupervised Learning, Semisupervised Learning, Reinforcement Learning, Batch Learning and Online Learning, Instance Based Learning and Model Based Learning from this Book. I have presented the simple Implementation of Linear Regression and KNearest Neighbors along with a simple plot using Python here in the Snapshot. I hope you will also spend some time reading the Topics and Book mentioned above. Excited about the days ahead!!
- Book:
  - **Hands On Machine Learning with Scikit Learn, Keras and TensorFlow**

![Image](https://github.com/ThinamXx/300Days__MachineLearningDeepLearning/blob/main/Images/Day%209a.PNG)

![Image](https://github.com/ThinamXx/300Days__MachineLearningDeepLearning/blob/main/Images/Day%209b.PNG)

**Day10 of 300DaysOfData!**
- On my Journey of Machine Learning and Deep Learning, Today I have read about the Main Challenges of Machine Learning such as Insufficient Quantity of Training Data, Non representative Training Data, Poor Quality Data, Irrelevant Features, Overfitting and Underfitting the Training Data and Testing and Validating, Hyperparameter Tuning and Model Selection and Data Mismatch from the Book **Hands On Machine Learning with Scikit Learn, Keras and TensorFlow**. I have started working on **California Housing Prices** Dataset which is included in this Book. I will build a Model of Housing Prices in California in this Project. I have presented the simple Implementation of Data Processing and few techniques of EDA using Python here in the Snapshot. I have also presented the Implementation of Sweetviz Library for Analysis here. I really appreciate Chanin Nantasenamat for sharing about this Library in one of his videos. I hope you will also spend some time reading the Topics and Book mentioned above. Excited about the days ahead!!
- Book:
  - **Hands On Machine Learning with Scikit Learn, Keras and TensorFlow**
- [**Chanin Nantasenamat Video on Sweetviz**](https://www.youtube.com/watch?v=UR_OK8vBpeY&lc=z22itptbrzv0vfky504t1aokgq4l23pa5kermfzdyrfkbk0h00410.1605764911555430)
- [**California Housing Prices**](https://github.com/ThinamXx/CaliforniaHousing__Prices.git)

![Image](https://github.com/ThinamXx/300Days__MachineLearningDeepLearning/blob/main/Images/Day%2010.PNG)

![Image](https://github.com/ThinamXx/300Days__MachineLearningDeepLearning/blob/main/Images/Day%2010b.PNG)

![Image](https://github.com/ThinamXx/300Days__MachineLearningDeepLearning/blob/main/Images/Day%2010a.PNG)

**Day11 of 300DaysOfData!**
- On my Journey of Machine Learning and Deep Learning, Today I have learned and Implemented about Creating categories from attributes, Stratified Sampling, Visualizing Data to gain insights, Scatter Plots, Correlations, Scatter Matrix and Attribute Combinations from the Book **Hands On Machine Learning with Scikit Learn, Keras and TensorFlow**. I have continued working with **California Housing Prices** Dataset which is included in this Book. This Dataset was based on Data from the 1990 California Census. I will build a Model of Housing Prices in California in this Project. I am still working on the same. I have presented the Implementation of Stratified Sampling, Correlations using Scatter Matrix and Attribute combinations using Python here in the Snapshots. I have also presented the Snapshots of Correlations using Scatter plots here. I hope you will spend some time working on the same and reading the Topics and Book mentioned above. Excited about the days ahead !! 
- Book:
  - **Hands On Machine Learning with Scikit Learn, Keras and TensorFlow**
- [**California Housing Prices**](https://github.com/ThinamXx/CaliforniaHousing__Prices.git)

![Image](https://github.com/ThinamXx/300Days__MachineLearningDeepLearning/blob/main/Images/Day%2011a.PNG)

![Image](https://github.com/ThinamXx/300Days__MachineLearningDeepLearning/blob/main/Images/Day%2011b.PNG)

![Image](https://github.com/ThinamXx/300Days__MachineLearningDeepLearning/blob/main/Images/Day%2011c.PNG)

**Day12 of 300DaysOfData!**
- On my Journey of Machine Learning and Deep Learning, Today I have learned and Implemented about Preparing the Data for Machine Learning Algorithms, Data Cleaning, Simple Imputer, Ordinal Encoder, OneHot Encoder, Feature Scaling, Transformation Pipeline, Standard Scaler, Column Transformer, Linear Regression, Decision Tree Regressor and Cross Validation from the Book **Hands On Machine Learning with Scikit Learn, Keras and TensorFlow**. I have continued working with **California Housing Prices** Dataset which is included in this Book. This Dataset was based on Data from the 1990 California Census. I will build a Model of Housing Prices in California in this Project. The Notebook contains almost every Topics mentioned above. I have presented the Implementation of Data Preparation, Handling missing values, OneHot Encoder, Column Transformer, Linear Regression, Decision Tree Regressor along with Cross Validation using Python here in the Snapshots. I hope you will spend some time working on the same and reading the Topics and Book mentioned above. Excited about the days ahead !!
- Book:
  - **Hands On Machine Learning with Scikit Learn, Keras and TensorFlow**
- [**California Housing Prices**](https://github.com/ThinamXx/CaliforniaHousing__Prices.git)

![Image](https://github.com/ThinamXx/300Days__MachineLearningDeepLearning/blob/main/Images/Day%2012a.PNG)

![Image](https://github.com/ThinamXx/300Days__MachineLearningDeepLearning/blob/main/Images/Day%2012b.PNG)

**Day13 of 300DaysOfData!**
- On my Journey of Machine Learning and Deep Learning, Today I have learned and Implemented about Random Forest Regressor, Ensemble Learning, Tuning the Model, Grid Search, Randomized Search, Analyzing the Best Models and Errors, Model Evaluation, Cross Validation and few more Topics related to the same from the Book **Hands On Machine Learning with Scikit Learn, Keras and TensorFlow**. I have completed working with **California Housing Prices** Dataset which is included in this Book. This Dataset was based on Data from the 1990 California Census. I have built a Model using Random Forest Regressor of California Housing Prices Dataset to predict the price of the Houses in California. I have presented the Implementation of Random Forest Regressor and Tuning the Model with Grid Search and Randomized Search along with Cross Validation using Python here in the Snapshot. I hope you will spend some time working on the same and reading the Topics and Book mentioned above. Excited about the days ahead!! 
- Book:
  - **Hands On Machine Learning with Scikit Learn, Keras and TensorFlow**
- [**California Housing Prices**](https://github.com/ThinamXx/CaliforniaHousing__Prices.git)

![Image](https://github.com/ThinamXx/300Days__MachineLearningDeepLearning/blob/main/Images/Day%2013.PNG)

**Day14 of 300DaysOfData!**
- **Confusion Matrix**: Confusion Matrix is a better way to evaluate the performance of a Classifier. The general idea of Confusion Matrix is to count the number of times instances of Class A are classified as Class B. This approach requires to have a set of predictions so that they can be compared to the actual targets. On my Journey of Machine Learning and Deep Learning, Today I have read and Implemented about Classification, Training a Binary Classifier using Stochastic Gradient Descent, Measuring Accuracy using Cross Validation, Implementation of CV, Confusion Matrix, Precision and Recall and their Curves and few more Topics related to the same from the Book **Hands On Machine Learning with Scikit Learn, Keras and TensorFlow**. I have presented the Implementation of SGD Classifier in MNIST Dataset along with Precision and Recall using Python here in the Snapshots. I have also presented the curves of Precision and Recall here. I hope you will spend some time working on the same and reading the Topics and Book mentioned above. I am excited about the days ahead!!
- Book:
  - **Hands On Machine Learning with Scikit Learn, Keras and TensorFlow**

![Image](https://github.com/ThinamXx/300Days__MachineLearningDeepLearning/blob/main/Images/Day%2014a.PNG)

![Image](https://github.com/ThinamXx/300Days__MachineLearningDeepLearning/blob/main/Images/Day%2014b.PNG)

![Image](https://github.com/ThinamXx/300Days__MachineLearningDeepLearning/blob/main/Images/Day%2014c.PNG)

**Day15 of 300DaysOfData!**
- On my Journey of Machine Learning and Deep Learning, Today I have read and Implemented about The ROC Curve, Random Forest Classifier, SGD Classifier, Multi Class Classification, One vs One and One vs All Strategies, Cross Validation, Error Analysis using Confusion Matrix, Multi Class Classification, KNeighbors Classifier, Multi Output Classification, Noises, Precision and Recall Tradeoff and few more Topics related to the same from the Book **Hands On Machine Learning with Scikit Learn, Keras and TensorFlow**. I have completed the Topic Classification from this Book. I have presented the Implementation of The ROC Curve, Random Forest Classifier in Multi Class Classification, The One vs One Strategy, Standard Scaler, Error Analysis, Multi Label Classification and Multi Output Classification using Scikit Learn here in the Snapshots. I hope you will also work on the same. I hope you will also spend some time reading the Topics and Book mentioned above. I am excited about the days ahead!!
- Book:
  - **Hands On Machine Learning with Scikit Learn, Keras and TensorFlow**
  
![Image](https://github.com/ThinamXx/300Days__MachineLearningDeepLearning/blob/main/Images/Day%2015a.PNG)

![Image](https://github.com/ThinamXx/300Days__MachineLearningDeepLearning/blob/main/Images/Day%2015b.PNG)

**Day16 of 300DaysOfData!**
- **Ridge Regression**: Ridge Regression is a regularized Linear Regression viz. a regularization term is added to the cost function which forces the learning algorithm to not only fit the Data but also keep the model weights as small as possible. On my Journey of Machine Learning and Deep Learning, Today I have read and Implemented about Training the Models, Linear Regression, The Normal Equations and Computational Complexity, Cost Function and Gradient Descent such as Batch Gradient Descent, Convergence Rate, Stochastic Gradient Descent, Mini batch Gradient Descent, Polynomial Regression and Poly Features, Learning Curves, Bias and Variance Tradeoff, Regularized Linear Models such as Ridge Regression and few more related to the same from the Book **Hands On Machine Learning with Scikit Learn, Keras and TensorFlow**. I have presented the Implementation of Polynomial Regression, Learning Curves and Ridge Regression along with Visualization using Python here in the Snapshots. I hope you will spend some time working on the same and reading the Topics and Book mentioned above. Excited about the days ahead!!
- Book:
  - **Hands On Machine Learning with Scikit Learn, Keras and TensorFlow**

![Image](https://github.com/ThinamXx/300Days__MachineLearningDeepLearning/blob/main/Images/Day%2016.PNG)

![Image](https://github.com/ThinamXx/300Days__MachineLearningDeepLearning/blob/main/Images/Day%2016b.PNG)

![Image](https://github.com/ThinamXx/300Days__MachineLearningDeepLearning/blob/main/Images/Day%2016a.PNG)

**Day17 of 300DaysOfData!**
- **Elastic Net**: Elastic Net is a middle grouped between Ridge Regression and Lasso Regression. The regularization term **r** is a simple mix of both Ridge and Lasso's regularization terms. When **r** equals 0, it is equivalent to Ridge and when **r** equals 1, it is equivalent to Lasso Regression. On my Journey of Machine Learning and Deep Learning, Today I have read and Implemented about Lasso Regression, Elastic Net, Early Stopping, SGD Regressor, Logistic Regression, Estimating Probabilities, Training and Cost Function, Sigmoid Function, Decision Boundaries, Softmax Regression or Multinomial Logistic Regression, Cross Entropy and few more Topics related to the same from the Book **Hands On Machine Learning with Scikit Learn, Keras and TensorFlow**. I have just started reading the Topic Support Vector Machines. I have presented the simple Implementation of Lasso Regression, Elastic Net, Early Stopping, Logistic Regression and Softmax Regression using Scikit Learn here in the Snapshots. I hope you will spend some time working on the same and reading the Topics and Book mentioned above. Excited about the days ahead!!
- Book:
  - **Hands On Machine Learning with Scikit Learn, Keras and TensorFlow**

![Image](https://github.com/ThinamXx/300Days__MachineLearningDeepLearning/blob/main/Images/Day%2017a.PNG)

![Image](https://github.com/ThinamXx/300Days__MachineLearningDeepLearning/blob/main/Images/Day%2017.PNG)

**Day18 of 300DaysOfData!**
- **Support Vector Machines**: A Support Vector Machines or SVM is a very powerful and versatile Machine Learning model which is capable of performing Linear and Nonlinear Classification, Regression and even outlier detection. SVMs are particularly well suited for classification of complex but medium sized datasets. On my Journey of Machine Learning and Deep Learning, Today I have read and Implemented about Support Vector Machines, Linear SVM Classification, Soft Margin Classification, Nonlinear SVM Classification, Polynomial Regression, Polynomial Kernel, Adding Similarity Features, Gaussian RBF Kernel, Computational Complexity, SVM Regression which is Linear as well Nonlinear and few more Topics related to the same from the Book **Hands On Machine Learning with Scikit Learn, Keras and TensorFlow**. I have presented the Implementation of Nonlinear SVM Classification using SVC and Linear SVC along with Visualization using Python here in the Snapshots. I hope you will spend some time working on the same and reading the Topics and Book mentioned above. Excited about the days ahead!!
- Book:
  - **Hands On Machine Learning with Scikit Learn, Keras and TensorFlow**

![Image](https://github.com/ThinamXx/300Days__MachineLearningDeepLearning/blob/main/Images/Day%2018a.PNG)

![Image](https://github.com/ThinamXx/300Days__MachineLearningDeepLearning/blob/main/Images/Day%2018b.PNG)

![Image](https://github.com/ThinamXx/300Days__MachineLearningDeepLearning/blob/main/Images/Day%2018c.PNG)

**Day19 of 300DaysOfData!**
- **Voting Classifiers**: Voting Classifiers are the classifiers which aggregates the predictions of different Classifiers and predicts the class that gets the most votes. The majority vote classifier is called a Hard Voting Classifier. On my Journey of Machine Learning and Deep Learning, Today I have read and Implemented about Ensemble Learning and Random Forests, Voting Classifiers such as Hard Voting and Soft Voting Classifiers and few more topics related to the same. Actually, I have also started working on a Research Project with an amazing Team. I have presented the Implementation of Hard Voting and Soft Voting Classifiers using Scikit Learn here in the Snapshots. I hope you will spend some time working on the same and reading the Topics mentioned above. Excited about the days ahead!!
- Book:
  - **Hands On Machine Learning with Scikit Learn, Keras and TensorFlow**

![Image](https://github.com/ThinamXx/300Days__MachineLearningDeepLearning/blob/main/Images/Day%2019a.PNG)


